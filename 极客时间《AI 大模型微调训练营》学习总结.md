经过一个学期的深入学习，极客时间《AI 大模型微调训练营》即将圆满结束。回顾这段时间的成长与收获，现做如下总结。

## 📌 个人背景

我目前从事 **Java 开发工作**，主要聚焦后端架构与系统设计。随着大语言模型（LLM）逐步走进主流应用领域，我希望能深入学习其核心原理与工程化落地方式，为未来转型做好准备。因此，我报名了此次训练营。

## 📚 课程内容回顾

本训练营课程设计系统、节奏紧凑，围绕 **大模型微调技术** 展开，分为理论讲解与工程实践两个维度，主要包括：

### 第一周：AI 大模型微调核心概览
- 了解大模型训练/微调流程与工程体系（Pre-training、Fine-tuning、SFT、RLHF、指令微调）
- 微调前的 Prompt 工程
- Prompt 架构演进与思考

### 第二周：大模型基础工具链与 Hugging Face 入门
- Hugging Face Transformers 核心模块详解
- 模型推理流程解析
- 使用 Datasets 与 Tokenizer 预处理数据
- Transformers 微调实战（BERT 任务）

### 第三周：PEFT 轻量参数微调技术详解
- Prompt Tuning、Prefix Tuning、LoRA 等方法对比与实战
- PEFT 工程落地路径讲解
- UniPELT、IA3 等前沿论文介绍

### 第四周：ChatGLM3 微调实战
- 了解 ChatGLM 系列模型原理
- 本地部署 ChatGLM3-6B 推理环境
- 微调 ChatGLM 模型 Demo 构建
- 多轮对话 Prompt 构建方法

### 第五周：ChatGPT 微调与强化学习 RLHF
- 学习 InstructGPT / ChatGPT 架构
- 人类反馈强化学习（RLHF）流程解析
- AI 安全对齐技术 RLHF 实践路线

### 第六周：专家模型 MoE 技术探索
- MoE 架构原理与挑战（门控机制、路由器设计）
- Switch Transformer、GLaM、TaskMoE 等前沿论文
- 混合专家技术的微调方法

### 第七周：LLaMA 系列模型与实战微调
- Meta LLaMA 模型架构详解
- 实战 LLaMA2-7B 微调流程
- 使用 LoRA+QLoRA 实现高效训练
- 模型推理加速：vLLM、TPU、INT4 等技术

### 第八周：模型加速框架 DeepSpeed 与国产模型探索
- DeepSpeed 技术体系与模块：ZeRO、Infty、Compression、MoE
- 实战部署：推理+压缩+多卡训练一体化
- Ascend910B 芯片环境下 ChatGLM-6B 的训练应用实践

## 🎯 我的收获

通过这次系统性训练，我收获如下：

1. **理论认知提升**：从只了解“大模型”概念，到掌握 SFT、LoRA、RLHF、MoE 等主流微调方法；
2. **实战能力提升**：实际完成 ChatGLM3 和 LLaMA 模型的推理部署与轻量化微调；
3. **工程工具熟练**：掌握 Hugging Face Transformers/Datasets/PEFT、Gradio、DeepSpeed 等核心工具链；
4. **未来方向更清晰**：了解大模型微调在企业中的落地路径，以及国产芯片/平台的适配趋势。


## ✅ 总结

极客时间这门《AI 大模型微调训练营》为我打开了进入 LLM 微调工程的大门，不仅理论讲得透，代码也带得细，真正做到了“教得明白，跟得上，做得出”。

感谢极客时间团队的用心打磨课程，感谢老师们认真负责的讲解与答疑，也感谢社群中每位热心的学习者。

接下来，我将继续在自己的项目中应用这些知识，推动 AI 在实际业务中的落地实践。
